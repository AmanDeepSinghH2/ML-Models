{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1138            6.3             0.510         0.13             2.3      0.076   \n",
       "1139            6.8             0.620         0.08             1.9      0.068   \n",
       "1140            6.2             0.600         0.08             2.0      0.090   \n",
       "1141            5.9             0.550         0.10             2.2      0.062   \n",
       "1142            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1138     11.0        6  \n",
       "1139      9.5        6  \n",
       "1140     10.5        5  \n",
       "1141     11.2        6  \n",
       "1142     10.2        5  \n",
       "\n",
       "[1143 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('WineQT.csv')\n",
    "df=df.drop(columns=['Id'])\n",
    "\n",
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1:].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.26578467  0.38239855 -0.9581086  ...  0.44053067 -0.69108098\n",
      "   0.51574115]\n",
      " [ 1.42480285 -1.17701572  0.87302251 ... -0.58120997  0.71799688\n",
      "  -0.4087107 ]\n",
      " [ 0.33711853 -0.73146879  0.26264547 ...  0.44053067  0.6592853\n",
      "   0.05351522]\n",
      " ...\n",
      " [ 0.85233742 -0.78716215  0.82215776 ... -0.77278634 -1.1607736\n",
      "   0.88552188]\n",
      " [-0.69331924 -0.06314838 -1.21243237 ...  1.20683616 -0.33881152\n",
      "  -0.59360107]\n",
      " [ 0.27987199 -1.12132236  0.72042825 ... -0.07033965 -0.22138836\n",
      "   1.53263818]]\n",
      "[[5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [7]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [8]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [8]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [8]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [7]\n",
      " [8]\n",
      " [7]\n",
      " [6]\n",
      " [4]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [8]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [8]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [3]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [8]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [3]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [8]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [3]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [3]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [8]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2,random_state=0)\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45161162  1.35703247 -0.24600206 ... -0.83664513 -0.86721572\n",
      "  -0.77849144]\n",
      " [-0.80781233  3.11137353 -1.05983811 ...  1.27069495 -1.33690833\n",
      "   0.88552188]\n",
      " [ 0.45161162  1.27349242  2.09377658 ... -2.62469126  3.94713364\n",
      "  -1.24071737]\n",
      " ...\n",
      " [ 0.33711853 -0.84285552  0.6695635  ... -0.26191602  0.54186214\n",
      "   1.9948641 ]\n",
      " [ 0.5661047   0.68871207 -0.04254305 ... -0.3896336  -1.39561991\n",
      "  -0.77849144]\n",
      " [ 0.27987199  0.60517202 -0.50032583 ... -0.51735118 -0.69108098\n",
      "  -0.77849144]]\n",
      "[[5]\n",
      " [4]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [8]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [7]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [8]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [7]\n",
      " [7]\n",
      " [7]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [7]\n",
      " [7]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [7]\n",
      " [6]\n",
      " [6]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [5]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(max_depth=5, min_samples_split=10, random_state=0)\n",
    "dtc.fit(x_train,y_train)\n",
    "y1_pred=dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.66      0.68      0.67       100\n",
      "           6       0.55      0.58      0.56        92\n",
      "           7       0.46      0.44      0.45        27\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.58       229\n",
      "   macro avg       0.28      0.28      0.28       229\n",
      "weighted avg       0.56      0.58      0.57       229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=100,max_depth=5,random_state=0)\n",
    "rfc.fit(x_train,y_train)\n",
    "y2_pred=rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.74      0.80      0.77       100\n",
      "           6       0.62      0.73      0.67        92\n",
      "           7       0.54      0.26      0.35        27\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67       229\n",
      "   macro avg       0.32      0.30      0.30       229\n",
      "weighted avg       0.64      0.67      0.65       229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\amand\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y2_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
