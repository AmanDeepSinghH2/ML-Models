{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\amand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12129.8.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    content = file.read()\n",
    "\n",
    "with open('positive-words.txt', 'r', encoding='ISO-8859-1') as f:\n",
    "    positive_words = set(f.read().splitlines())\n",
    "\n",
    "with open('negative-words.txt', 'r', encoding='ISO-8859-1') as f:\n",
    "    negative_words = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stopwords = set(stopwords.words('english')) | positive_words | negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machin learn affect busi ?',\n",
       " 'machin learn techniqu may use year , recent explos applic .',\n",
       " 'fact , recent q3 earn call , googl ceo sundar pichai said â\\x80\\x9cmachin learn core , transform way weâ\\x80\\x99r re-think weâ\\x80\\x99r everything.â\\x80\\x9d theyâ\\x80\\x99r far busi make claim .',\n",
       " 'past , use machin learn algorithm requir bespok algorithm huge r & budget , chang .',\n",
       " 'ibm watson , microsoft azur , amazon , alibaba launch turnkey cloud-bas machine-learn saa solut 2015 .',\n",
       " 'time startup idibon , metamind , dato , monkeylearn built machin learn product compani take .',\n",
       " 'gartner alreadi put machin learn curv , : machin learn wonâ\\x80\\x99t replac employe comput sudden doubl revenu .',\n",
       " 'doesnâ\\x80\\x99t mean canâ\\x80\\x99t give everi busi .',\n",
       " 'plenti busi process signific machin learn .',\n",
       " 'machin learn chang way busi oper ?',\n",
       " 'fig : machin learn techniqu busi bigger upfront cost first thingâ\\x80\\x99 first : machin learn need train data train data cost money .',\n",
       " 'especi train data label human .',\n",
       " 'let explain .',\n",
       " 'make machin learn busi , algorithm need see lot lot exampl itâ\\x80\\x99 suppos .',\n",
       " 'want algorithm tell sale , need show lot lot exampl sale sale .',\n",
       " 'want algorithm tag ticket need show mani exampl ticket .',\n",
       " 'local algorithm new languag probabl need collect lot exampl languag .',\n",
       " 'instanc , compani may train set in-hous .',\n",
       " 'exampl , bunch disqualifi .',\n",
       " 'say havenâ\\x80\\x99t label ticket theyâ\\x80\\x99v come year .',\n",
       " 'youâ\\x80\\x99d need peopl either in-hous en mass via data platform -label ticket .',\n",
       " 'machin look judgment start find connect pattern learn .',\n",
       " 'much lower ongo cost machin learn much peopl .',\n",
       " 'often 80 percent case 20 percent case , lower 20 percent rate , .',\n",
       " 'even 80 percent algorithm save lot money machin learn algorithm know like .',\n",
       " 'compani take case algorithm high use direct send low case human .',\n",
       " 'bank year .',\n",
       " 'put check atm , algorithm tri deciph number check .',\n",
       " 'realli handwrit ink algorithm pass task human .',\n",
       " 'design pattern save bank lot money preserv high level accuraci .',\n",
       " 'cost drop time huge machin learn turn part variabl cost fix cost .',\n",
       " 'use human handl case algorithm , creat train data feed algorithm .',\n",
       " 'well-studi techniqu call activ learn turn train data label collect case algorithm low help algorithm learn much , much .',\n",
       " 'algorithm becom increas , unit econom busi process becom machin learn becom abl handl case , human call , rarest situat .',\n",
       " 'mean use human machin tandem : leverag speed reliabl comput judgment fluenci expertis human one .',\n",
       " 'sound busi , itâ\\x80\\x99 .',\n",
       " 'blackcoff insight 28 : monica v , sns colleg technolog']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences = []\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    filtered_words = [stemmer.stem(word) for word in words if word.lower() not in combined_stopwords]\n",
    "    processed_sentences.append(' '.join(filtered_words))\n",
    "\n",
    "processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 1.684848484848485\n",
      "Negative Score: 0.4166666666666667\n",
      "Average Sentence Length: 11.702702702702704\n",
      "Percent of Complex Words: 9.930715935334874\n",
      "Fog Index: 8.653367455215031\n",
      "Complex Word Count: 43\n",
      "Total Word Count: 433\n",
      "Personal Pronoun Count: 0\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import syllapy\n",
    "\n",
    "personal_pronouns = {'i', 'me', 'my', 'we', 'our', 'ours', 'us', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'they', 'them', 'their', 'theirs'}\n",
    "total_words = complex_word_count = personal_pronoun_count = positive_score = negative_score = 0\n",
    "\n",
    "for sentence in processed_sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    total_words += len(words)\n",
    "    complex_word_count += sum(1 for word in words if syllapy.count(word) >= 3)\n",
    "    personal_pronoun_count += sum(1 for word in words if word.lower() in personal_pronouns)\n",
    "    \n",
    "    sentiment = TextBlob(sentence).sentiment.polarity\n",
    "    positive_score += max(sentiment, 0)\n",
    "    negative_score += abs(min(sentiment, 0))\n",
    "\n",
    "avg_sentence_length = total_words / len(processed_sentences)\n",
    "percent_complex_words = (complex_word_count / total_words) * 100\n",
    "fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
    "\n",
    "print(\"Positive Score:\", positive_score)\n",
    "print(\"Negative Score:\", negative_score)\n",
    "print(\"Average Sentence Length:\", avg_sentence_length)\n",
    "print(\"Percent of Complex Words:\", percent_complex_words)\n",
    "print(\"Fog Index:\", fog_index)\n",
    "print(\"Complex Word Count:\", complex_word_count)\n",
    "print(\"Total Word Count:\", total_words)\n",
    "print(\"Personal Pronoun Count:\", personal_pronoun_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
